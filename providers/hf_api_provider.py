"""
–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Hugging Face API
"""

import os
import asyncio
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from huggingface_hub import InferenceClient

from .base_provider import BaseProvider

class HFApiProvider(BaseProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Hugging Face Inference API"""
    
    def __init__(self):
        super().__init__(
            name="Hugging Face API",
            description="–ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Hugging Face Inference API (Stable Diffusion XL)"
        )
        self.client: Optional[InferenceClient] = None
        self.available_models = [
            "stabilityai/stable-diffusion-xl-base-1.0",
            "runwayml/stable-diffusion-v1-5",
            "CompVis/stable-diffusion-v1-4"
        ]
        self.current_model = self.available_models[0]  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é SDXL
    
    async def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        try:
            load_dotenv()
            hf_token = os.getenv("HF_TOKEN")
            
            if not hf_token:
                print("‚ùå HF_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
                return False
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            self.client = await self._run_sync_in_async(
                lambda: InferenceClient(api_key=hf_token)
            )
            
            self.is_initialized = True
            print(f"‚úÖ {self.name} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ {self.name}: {e}")
            return False
    
    async def generate_image(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Hugging Face API
        
        Args:
            prompt: –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
                - model: str - –º–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                - width: int - —à–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1024)
                - height: int - –≤—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1024)
                - num_inference_steps: int - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 20)
                - guidance_scale: float - —Å–∏–ª–∞ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 7.5)
        """
        if not self.is_available():
            return {
                "success": False,
                "error": "–ü—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
            }
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            model = kwargs.get("model", self.current_model)
            width = kwargs.get("width", 1024)
            height = kwargs.get("height", 1024)
            num_inference_steps = kwargs.get("num_inference_steps", 20)
            guidance_scale = kwargs.get("guidance_scale", 7.5)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            image_path = self._generate_filename(prompt)
            
            print(f"üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ {model}...")
            print(f"üìù –ü—Ä–æ–º–ø—Ç: {prompt}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            image = await self._run_sync_in_async(
                self._generate_image_sync,
                prompt=prompt,
                model=model,
                width=width,
                height=height,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            await self._run_sync_in_async(image.save, image_path)
            
            print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {image_path}")
            
            return {
                "success": True,
                "image_path": image_path,
                "metadata": {
                    "model": model,
                    "prompt": prompt,
                    "width": width,
                    "height": height,
                    "num_inference_steps": num_inference_steps,
                    "guidance_scale": guidance_scale,
                    "provider": self.name
                }
            }
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ {self.name}: {str(e)}"
            print(f"‚ùå {error_msg}")
            return {
                "success": False,
                "error": error_msg
            }
    
    def _generate_image_sync(self, prompt: str, model: str, width: int, height: int, 
                           num_inference_steps: int, guidance_scale: float):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        return self.client.text_to_image(
            prompt=prompt,
            model=model,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale
        )
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        return self.is_initialized and self.client is not None
    
    def set_model(self, model: str) -> bool:
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        
        Args:
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            
        Returns:
            True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
        """
        if model in self.available_models:
            self.current_model = model
            return True
        return False
    
    def get_available_models(self) -> list:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        return self.available_models.copy()
    
    def get_current_model(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å"""
        return self.current_model
